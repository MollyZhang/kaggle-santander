4-26-2016
1.  original number of features: 371,
    0-variance features: 34,
    duplicate features: 29,
    linearly covariate features: 21
    remove all, now we have 287 features

using XGBoost, learning curve:
sample train       val
1000   0.936551  0.768611
6000   0.875586  0.827448
11000  0.863039  0.824784
16000  0.858613  0.823298
21000  0.854142  0.828317
26000  0.851990  0.830302
31000  0.849438  0.829749
36000  0.847078  0.829305
41000  0.845280  0.828891
46000  0.842998  0.829130
51000  0.842585  0.829975
56000  0.843980  0.830870


4-27-2016
# try standard scaling before xgboost, no improvement

Standard scaler:


         train       val
1000   0.937578  0.767022
6000   0.876515  0.826633
11000  0.862059  0.822700
16000  0.857819  0.821216
21000  0.853662  0.826837
26000  0.852457  0.827925
31000  0.849403  0.827920
36000  0.846144  0.828047
41000  0.843910  0.827878
46000  0.841545  0.827988
51000  0.842141  0.829570
56000  0.843322  0.829130

MinMaxScaler

          train       val
1000   0.933029  0.766719
6000   0.865396  0.823502
11000  0.844109  0.821703
16000  0.843553  0.817138
21000  0.840626  0.821941
26000  0.833998  0.821573
31000  0.831242  0.822713
36000  0.829197  0.820404
41000  0.826873  0.819998
46000  0.824804  0.819725
51000  0.824895  0.820356
56000  0.825184  0.819691



4-28
remove a lot more features with almost no variance or highly correlated with others
now total number of features 247




